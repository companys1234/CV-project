import cv2
import torchvision
import torchvision.transforms as transforms
import torch
import torch.nn as nn
from torchvision import models
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np
import time
from PIL import Image

# =================== 1. –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ö–õ–ê–°–°–û–í CIFAR-10 ===================
CIFAR10_CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']

# =================== 2. –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ò –ò –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===================
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç CIFAR-10 (—É –≤–∞—Å –±—ã–ª–æ CIFAR10 –≤ –∫–æ–¥–µ)
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)


# =================== 3. –°–û–ó–î–ê–ù–ò–ï –ò –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò ===================
def create_model():
    """–°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–¥–µ–ª—å ResNet18 –¥–ª—è CIFAR-10"""
    model = models.resnet18(pretrained=True)

    # –ò–∑–º–µ–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –¥–ª—è CIFAR-10 (10 –∫–ª–∞—Å—Å–æ–≤)
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, 10)

    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ CPU (–∏–ª–∏ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    model = model.to(device)

    return model, device


def train_model(model, trainloader, device, num_epochs=5):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    print("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    for epoch in range(num_epochs):
        running_loss = 0.0
        correct = 0
        total = 0

        for i, (inputs, labels) in enumerate(trainloader):
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            if i % 100 == 99:
                print(f'Epoch [{epoch + 1}/{num_epochs}], '
                      f'Batch [{i + 1}/{len(trainloader)}], '
                      f'Loss: {running_loss / 100:.4f}, '
                      f'Accuracy: {100 * correct / total:.2f}%')
                running_loss = 0.0

    print('–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!')
    return model


# =================== 4. –§–£–ù–ö–¶–ò–ò –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò –ö–ê–î–†–û–í ===================
def preprocess_frame_for_model(frame, device):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–∞–¥—Ä–∞ –∫–∞–º–µ—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏"""
    # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–æ 32x32 –∫–∞–∫ –≤ CIFAR-10
    frame_resized = cv2.resize(frame, (32, 32))

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR (OpenCV) –≤ RGB
    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL Image
    pil_image = Image.fromarray(frame_rgb)

    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    input_tensor = transform(pil_image)

    # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
    input_batch = input_tensor.unsqueeze(0)

    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    input_batch = input_batch.to(device)

    return input_batch, frame_resized


def predict_frame(model, frame, device):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –¥–ª—è –∫–∞–¥—Ä–∞"""
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–∞–¥—Ä
    input_batch, frame_resized = preprocess_frame_for_model(frame, device)

    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    with torch.no_grad():
        model.eval()
        outputs = model(input_batch)
        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)

    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    top3_prob, top3_catid = torch.topk(probabilities, 3)

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    predictions = []
    for i in range(top3_prob.size(0)):
        class_id = top3_catid[i].item()
        class_name = CIFAR10_CLASSES[class_id]
        confidence = top3_prob[i].item()
        predictions.append((class_name, confidence))

    return predictions, frame_resized


# =================== 5. –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –° –î–í–£–ú–Ø –û–ö–ù–ê–ú–ò ===================
def real_time_classification_with_dual_window(camera_id=0):
    """–ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å –¥–≤—É–º—è –æ–∫–Ω–∞–º–∏"""

    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...")
    model, device = create_model()

    # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –∑–∞–Ω–æ–≤–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ:
    # model = train_model(model, trainloader, device, num_epochs=5)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    # model.load_state_dict(torch.load('cifar10_resnet18.pth', map_location=device))

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∫–∞–º–µ—Ä—É
    cap = cv2.VideoCapture(camera_id)
    if not cap.isOpened():
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–∞–º–µ—Ä–µ")
        return

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–º–µ—Ä—ã
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    # –°–æ–∑–¥–∞–µ–º –æ–∫–Ω–∞
    cv2.namedWindow('üì∑ –ö–∞–º–µ—Ä–∞', cv2.WINDOW_NORMAL)
    cv2.namedWindow('ü§ñ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è', cv2.WINDOW_NORMAL)

    # –†–∞–∑–º–µ—â–∞–µ–º –æ–∫–Ω–∞ —Ä—è–¥–æ–º
    cv2.resizeWindow('üì∑ –ö–∞–º–µ—Ä–∞', 640, 480)
    cv2.resizeWindow('ü§ñ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è', 640, 480)
    cv2.moveWindow('üì∑ –ö–∞–º–µ—Ä–∞', 100, 100)
    cv2.moveWindow('ü§ñ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è', 750, 100)

    # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è FPS
    last_prediction_time = time.time()
    prediction_interval = 1.0  # 1 –∫–∞–¥—Ä –≤ —Å–µ–∫—É–Ω–¥—É
    last_predictions = []
    last_processed_frame = None

    print("\n" + "=" * 60)
    print("–°–ò–°–¢–ï–ú–ê –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –í –†–ï–ê–õ–¨–ù–û–ú –í–†–ï–ú–ï–ù–ò")
    print("=" * 60)
    print("–õ–µ–≤–æ–µ –æ–∫–Ω–æ: –ü—Ä—è–º–æ–π —ç—Ñ–∏—Ä —Å –∫–∞–º–µ—Ä—ã")
    print("–ü—Ä–∞–≤–æ–µ –æ–∫–Ω–æ: –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è 1 —Ä–∞–∑ –≤ —Å–µ–∫—É–Ω–¥—É)")
    print("\n–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:")
    print("  'q' - –í—ã—Ö–æ–¥")
    print("  's' - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
    print("  '1' - –£–≤–µ–ª–∏—á–∏—Ç—å –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–æ 2 —Å–µ–∫")
    print("  '2' - –£–º–µ–Ω—å—à–∏—Ç—å –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–æ 0.5 —Å–µ–∫")
    print("  ' ' (–ø—Ä–æ–±–µ–ª) - –°–¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫ —Å–µ–π—á–∞—Å")
    print("=" * 60)

    frame_count = 0
    start_time = time.time()

    while True:
        # –ß–∏—Ç–∞–µ–º –∫–∞–¥—Ä —Å –∫–∞–º–µ—Ä—ã
        ret, frame = cap.read()
        if not ret:
            print("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞")
            break

        frame_count += 1

        # ============ –õ–ï–í–û–ï –û–ö–ù–û: –ö–ê–ú–ï–†–ê ============
        camera_display = frame.copy()

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ –∫–∞–¥—Ä –∫–∞–º–µ—Ä—ã
        current_time = time.time()
        fps = frame_count / (current_time - start_time)

        # –í—Ä–µ–º—è –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        time_to_next = max(0, prediction_interval - (current_time - last_prediction_time))

        # –¢–µ–∫—Å—Ç–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        info_lines = [
            f"FPS: {fps:.1f}",
            f"–ö–∞–¥—Ä: {frame_count}",
            f"–°–ª–µ–¥—É—é—â–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —á–µ—Ä–µ–∑: {time_to_next:.1f}—Å",
            f"–ò–Ω—Ç–µ—Ä–≤–∞–ª: {prediction_interval}—Å"
        ]

        y_offset = 30
        for line in info_lines:
            cv2.putText(camera_display, line, (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            y_offset += 25

        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—é
        if time_to_next < 0.1:  # –ü–æ—á—Ç–∏ –≤—Ä–µ–º—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            cv2.circle(camera_display, (600, 40), 15, (0, 255, 0), -1)
        else:
            cv2.circle(camera_display, (600, 40), 15, (0, 0, 255), -1)

        cv2.imshow('üì∑ –ö–∞–º–µ—Ä–∞', camera_display)

        # ============ –ü–†–ê–í–û–ï –û–ö–ù–û: –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø ============
        current_time = time.time()
        make_prediction = False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª–∞–≤–∏—à–∏ –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        key = cv2.waitKey(1) & 0xFF

        if key == ord(' '):  # –ü—Ä–æ–±–µ–ª - –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–µ–π—á–∞—Å
            make_prediction = True
        elif current_time - last_prediction_time >= prediction_interval:
            make_prediction = True

        if make_prediction:
            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            predictions, processed_frame = predict_frame(model, frame, device)
            last_predictions = predictions
            last_processed_frame = processed_frame
            last_prediction_time = current_time

            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∫–æ–Ω—Å–æ–ª—å
            print(f"\n[{time.strftime('%H:%M:%S')}] –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ #{frame_count}:")
            for i, (class_name, confidence) in enumerate(predictions):
                print(f"  {i + 1}. {class_name}: {confidence:.1%}")

        # –°–æ–∑–¥–∞–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ–∫–Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        if last_processed_frame is not None and len(last_predictions) > 0:
            # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            classification_display = np.zeros((480, 640, 3), dtype=np.uint8)
            classification_display[:] = (40, 40, 40)  # –¢–µ–º–Ω–æ-—Å–µ—Ä—ã–π —Ñ–æ–Ω

            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–∞–¥—Ä (—É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π)
            small_frame = cv2.resize(last_processed_frame, (200, 200))
            classification_display[50:250, 50:250] = cv2.cvtColor(small_frame, cv2.COLOR_RGB2BGR)

            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            cv2.putText(classification_display, "–†–ï–ó–£–õ–¨–¢–ê–¢ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò",
                        (260, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_offset = 100
            for i, (class_name, confidence) in enumerate(last_predictions):
                # –¶–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if confidence > 0.7:
                    color = (0, 255, 0)  # –ó–µ–ª–µ–Ω—ã–π
                elif confidence > 0.3:
                    color = (0, 255, 255)  # –ñ–µ–ª—Ç—ã–π
                else:
                    color = (0, 165, 255)  # –û—Ä–∞–Ω–∂–µ–≤—ã–π

                # –¢–µ–∫—Å—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                text = f"{i + 1}. {class_name}: {confidence:.1%}"
                cv2.putText(classification_display, text,
                            (260, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

                # –ü–æ–ª–æ—Å–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                bar_width = int(confidence * 200)
                cv2.rectangle(classification_display,
                              (260, y_offset + 10),
                              (260 + bar_width, y_offset + 25),
                              color, -1)

                y_offset += 50

            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            time_text = f"–û–±–Ω–æ–≤–ª–µ–Ω–æ: {time.strftime('%H:%M:%S', time.localtime(last_prediction_time))}"
            cv2.putText(classification_display, time_text,
                        (260, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)

            # –õ–µ–≥–µ–Ω–¥–∞
            cv2.putText(classification_display, "–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (>70%)",
                        (260, 430), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
            cv2.putText(classification_display, "–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (30-70%)",
                        (260, 450), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            cv2.putText(classification_display, "–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (<30%)",
                        (260, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 165, 255), 1)

            cv2.imshow('ü§ñ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è', classification_display)
        else:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ–∂–∏–¥–∞–Ω–∏–∏
            waiting_display = np.zeros((480, 640, 3), dtype=np.uint8)
            cv2.putText(waiting_display, "–û–ñ–ò–î–ê–ù–ò–ï –ü–ï–†–í–û–ì–û –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø...",
                        (150, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
            cv2.imshow('ü§ñ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è', waiting_display)

        # ============ –û–ë–†–ê–ë–û–¢–ö–ê –ö–õ–ê–í–ò–® ============
        if key == ord('q'):  # –í—ã—Ö–æ–¥
            break
        elif key == ord('s'):  # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if last_processed_frame is not None:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä
                cv2.imwrite(f'capture_{timestamp}.jpg', frame)
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                with open(f'results_{timestamp}.txt', 'w') as f:
                    f.write(f"–í—Ä–µ–º—è: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"–ö–∞–¥—Ä: {frame_count}\n")
                    f.write("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:\n")
                    for i, (class_name, confidence) in enumerate(last_predictions):
                        f.write(f"  {i + 1}. {class_name}: {confidence:.1%}\n")
                print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: capture_{timestamp}.jpg –∏ results_{timestamp}.txt")
        elif key == ord('1'):  # –£–≤–µ–ª–∏—á–∏—Ç—å –∏–Ω—Ç–µ—Ä–≤–∞–ª
            prediction_interval = 2.0
            print(f"–ò–Ω—Ç–µ—Ä–≤–∞–ª –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ {prediction_interval} —Å–µ–∫")
        elif key == ord('2'):  # –£–º–µ–Ω—å—à–∏—Ç—å –∏–Ω—Ç–µ—Ä–≤–∞–ª
            prediction_interval = 0.5
            print(f"–ò–Ω—Ç–µ—Ä–≤–∞–ª –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ {prediction_interval} —Å–µ–∫")

    # ============ –ó–ê–í–ï–†–®–ï–ù–ò–ï ============
    total_time = time.time() - start_time
    print("\n" + "=" * 60)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–ë–û–¢–´:")
    print("=" * 60)
    print(f"–í—Å–µ–≥–æ –∫–∞–¥—Ä–æ–≤: {frame_count}")
    print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f} —Å–µ–∫")
    print(f"–°—Ä–µ–¥–Ω–∏–π FPS: {frame_count / total_time:.1f}")

    # –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
    cap.release()
    cv2.destroyAllWindows()


# =================== 6. –ó–ê–ü–£–°–ö –ü–†–û–ì–†–ê–ú–ú–´ ===================
if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∫–∞–º–µ—Ä—ã
    def check_camera():
        for i in range(3):
            cap_test = cv2.VideoCapture(i)
            if cap_test.isOpened():
                print(f"–ù–∞–π–¥–µ–Ω–∞ –∫–∞–º–µ—Ä–∞ —Å –∏–Ω–¥–µ–∫—Å–æ–º {i}")
                cap_test.release()
                return i
            cap_test.release()
        return 0


    camera_id = check_camera()

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    real_time_classification_with_dual_window(camera_id)